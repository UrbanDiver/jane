# Log Analysis and Fixes

**Date:** 2025-12-01  
**Analysis:** Examined recent logs for problems

---

## üîç Problems Identified

### 1. TTS Tensor Size Mismatch Errors ‚ùå

**Error:**
```
RuntimeError: The size of tensor a (29) must match the size of tensor b (27) at non-singleton dimension 1
RuntimeError: The size of tensor a (15) must match the size of tensor b (77) at non-singleton dimension 1
```

**Root Cause:**
- Tacotron2 TTS model has internal attention state that gets corrupted
- Happens when processing multiple short sentences in quick succession during streaming
- The model's `attention_weights_cum` accumulates incorrectly when sentence lengths differ

**Location:** `src/backend/assistant_core.py` - `_process_streaming_response()` method

**Fix Applied:**
1. ‚úÖ Changed streaming TTS to synthesize full response at once (instead of sentence-by-sentence)
2. ‚úÖ Added error handling with model reset fallback
3. ‚úÖ Added graceful degradation: if full synthesis fails, fall back to sentence-by-sentence with error handling

**Expected Result:** Eliminates tensor size mismatch errors

---

### 2. LLM Function Calling Still Slow ‚ö†Ô∏è

**Observation:**
- First LLM call: **36.136s** (still very slow!)
- Second LLM call: **34.537s** (still very slow!)

**Root Cause:**
- Optimizations haven't been applied yet (requires restart)
- Context window was increased to 2048 (fixes context overflow)
- But max_tokens reduction and temperature optimization need restart

**Status:** 
- ‚úÖ Config updated (max_tokens=64 for function calling, temperature=0.3)
- ‚è≥ **Requires restart** to take effect

**Expected After Restart:**
- First LLM call: ~10-15s (down from 36s)
- 60-70% improvement

---

## ‚úÖ Fixes Applied

### Fix 1: TTS Streaming Synthesis
**File:** `src/backend/assistant_core.py`

**Change:**
- Synthesize full response at once after streaming completes
- Avoids Tacotron2 state corruption from sentence-by-sentence processing
- Added fallback to sentence-by-sentence with error handling if full synthesis fails

### Fix 2: TTS Error Handling
**File:** `src/backend/tts_engine.py`

**Change:**
- Added specific handling for tensor size mismatch errors
- Automatically resets TTS model state and retries synthesis
- Graceful error handling prevents crashes

---

## üìä Performance Summary

| Component | Current | After Restart | Status |
|-----------|---------|---------------|---------|
| **TTS Errors** | Frequent | ‚úÖ Fixed | ‚úÖ Applied |
| **LLM Function Calling** | 34-36s | ~10-15s | ‚è≥ Needs restart |
| **Context Window** | 1024 (too small) | 2048 | ‚è≥ Needs restart |

---

## üöÄ Next Steps

1. **Restart the assistant** to apply LLM optimizations
2. **Test TTS** - verify no more tensor errors
3. **Monitor logs** - check LLM performance after restart

---

## üìù Technical Notes

### Why TTS Errors Occurred

Tacotron2 uses an attention mechanism with cumulative weights (`attention_weights_cum`). When processing multiple sentences:
1. First sentence processes correctly
2. Second sentence starts with corrupted state from first
3. Tensor sizes don't match ‚Üí RuntimeError

### Solution

Synthesize the full response at once:
- Single synthesis call = no state corruption
- Better quality (full context)
- Slightly higher latency but more reliable

### Fallback Strategy

If full synthesis fails:
1. Try sentence-by-sentence with error handling
2. Skip sentences that fail (don't crash)
3. Log errors for debugging

---

**Status:** ‚úÖ TTS fixes applied, ‚è≥ LLM optimizations pending restart

